import numpy as np
import cv2
import cv2.aruco as aruco
import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image, CameraInfo
from geometry_msgs.msg import PoseStamped, TransformStamped
from std_msgs.msg import Header
from cv_bridge import CvBridge
import time
import tf2_ros
from scipy.spatial.transform import Rotation as R

class D435MultiCameraArucoDetector(Node):
    def __init__(self):
        super().__init__('d435_multi_camera_aruco_detector')
        
        # ë¡œë´‡ ë§ˆì»¤ë“¤ (0~3ë²ˆ) - ë¡œì»¬ ì¢Œí‘œê³„
        self.robot_markers_local = {
            0: np.array([0.3, 0.135, 0.0]),
            1: np.array([0.3, -0.135, 0.0]),
            2: np.array([-0.3, -0.135, 0.0]),
            3: np.array([-0.3, 0.135, 0.0])
        }
    
        self.marker_length = 0.075  # ë§ˆì»¤ í¬ê¸°
        
        # ì›”ë“œ ì¢Œí‘œê³„ ì„¤ì • ìƒíƒœ
        self.world_established = False
        
        # ğŸ†• ë‹¤ì¤‘ ì¹´ë©”ë¼ ì„¤ì •
        self.cameras = {
            'camera1': {
                'topics': {
                    'image': '/camera1/camera1/color/image_raw',
                    'info': '/camera1/camera1/color/camera_info'
                },
                'camera_matrix': None,
                'dist_coeffs': None,
                'info_received': False,
                'H_world2cam': None,
                'latest_detections': {},
                'detection_timestamp': None
            },
            'camera3': {
                'topics': {
                    'image': '/camera3/camera3/color/image_raw', 
                    'info': '/camera3/camera3/color/camera_info'
                },
                'camera_matrix': None,
                'dist_coeffs': None,
                'info_received': False,
                'H_world2cam': None,
                'latest_detections': {},
                'detection_timestamp': None
            }
        }
        
        # ë¡œë´‡ ì¤‘ì‹¬ ì¶”ì  (í†µí•©ëœ ê²°ê³¼)
        self.latest_robot_center = None
        self.center_timestamp = None
        
        # ArUco ì„¤ì •
        self.aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_4X4_50)
        self.aruco_params = cv2.aruco.DetectorParameters()

        # ë³€í™˜ í–‰ë ¬ë“¤ (í†µí•©ëœ ê²°ê³¼)
        self.H_world2cam_global = None  # ê¸€ë¡œë²Œ ì›”ë“œâ†’ì¹´ë©”ë¼ (ì²« ë²ˆì§¸ë¡œ 10ë²ˆ ë§ˆì»¤ë¥¼ ë³¸ ì¹´ë©”ë¼ ê¸°ì¤€)
        self.H_cam2robot = None         # ì¹´ë©”ë¼â†’ë¡œë´‡ ì¤‘ì‹¬
        self.H_world2robot = None       # ì›”ë“œâ†’ë¡œë´‡
        
        self.tf_broadcaster = tf2_ros.TransformBroadcaster(self)

        # ğŸ†• ê° ì¹´ë©”ë¼ë³„ êµ¬ë…ì ì„¤ì •
        self.setup_camera_subscriptions()
        
        # ë°œí–‰ì
        self.robot_center_pub = self.create_publisher(
            PoseStamped, '/robot_center', 10
        )
        
        # ğŸ†• ì£¼ê¸°ì ìœ¼ë¡œ ë‹¤ì¤‘ ì¹´ë©”ë¼ ë°ì´í„° ìœµí•©
        self.create_timer(0.1, self.fuse_multi_camera_data)  # 10Hz
        
        self.get_logger().info("D435 Multi-Camera ArUco Detector initialized")

    def setup_camera_subscriptions(self):
        """ê° ì¹´ë©”ë¼ë³„ êµ¬ë…ì ì„¤ì • (ê°„ë‹¨í•œ ë°©ë²•)"""
        available_cameras = list(self.cameras.keys())
        
        for camera_name in available_cameras:
            # ê¸°ë³¸ í† í”½ íŒ¨í„´
            image_topic = f'/{camera_name}/{camera_name}/color/image_raw'
            info_topic = f'/{camera_name}/{camera_name}/color/camera_info'

            # âœ… lambdaì—ì„œ ê¸°ë³¸ê°’ ì‚¬ìš©í•´ì„œ ë°”ì¸ë”© ë¬¸ì œ í•´ê²°
            self.create_subscription(
                Image, 
                image_topic, 
                lambda msg, name=camera_name: self.image_callback(msg, name), 
                10
            )
            
            self.create_subscription(
                CameraInfo, 
                info_topic, 
                lambda msg, name=camera_name: self.camera_info_callback(msg, name), 
                10
            )
            
            self.get_logger().info(f"Subscribed to {image_topic} and {info_topic}")

    def create_camera_subscription(self, camera_name, camera_config):
        """ê°œë³„ ì¹´ë©”ë¼ êµ¬ë…ì ìƒì„±"""
        
        # ì´ë¯¸ì§€ êµ¬ë…ì
        def image_callback_wrapper(msg):
            return self.image_callback(msg, camera_name)
        
        def camera_info_callback_wrapper(msg):
            return self.camera_info_callback(msg, camera_name)
        
        self.create_subscription(
            Image, 
            camera_config['topics']['image'], 
            image_callback_wrapper,
            10
        )
        
        self.create_subscription(
            CameraInfo, 
            camera_config['topics']['info'],
            camera_info_callback_wrapper,
            10
        )
        
        self.get_logger().info(f"ğŸ“· Created subscriptions for {camera_name}")

    def camera_info_callback(self, msg, camera_name):
        """ì¹´ë©”ë¼ ë‚´ë¶€ ë§¤ê°œë³€ìˆ˜ ìˆ˜ì‹ """
        camera_config = self.cameras[camera_name]
        
        if not camera_config['info_received']:
            camera_config['camera_matrix'] = np.array(msg.k).reshape(3, 3)
            camera_config['dist_coeffs'] = np.array(msg.d)
            camera_config['info_received'] = True
            self.get_logger().info(f"ğŸ“· {camera_name} intrinsics received")

    def image_callback(self, msg, camera_name):
        """ê° ì¹´ë©”ë¼ë³„ ì´ë¯¸ì§€ ì²˜ë¦¬ ë° ArUco ê²€ì¶œ"""
        camera_config = self.cameras[camera_name]
        
        if not camera_config['info_received']:
            return
            
        bridge = CvBridge()
        cv_image = bridge.imgmsg_to_cv2(msg, desired_encoding='bgr8')
        gray = cv2.cvtColor(cv_image, cv2.COLOR_BGR2GRAY)

        # ArUco ë§ˆì»¤ ê²€ì¶œ
        detector = aruco.ArucoDetector(self.aruco_dict, self.aruco_params)
        corners, ids, _ = detector.detectMarkers(gray)

        if ids is None:
            # ê²€ì¶œ ì‹¤íŒ¨ì‹œ íƒ€ì„ìŠ¤íƒ¬í”„ë§Œ ì—…ë°ì´íŠ¸
            camera_config['latest_detections'] = {}
            camera_config['detection_timestamp'] = time.time()
            return

        # í¬ì¦ˆ ì¶”ì • (í•´ë‹¹ ì¹´ë©”ë¼ ì¢Œí‘œê³„)
        try:
            rvecs, tvecs, _ = cv2.aruco.estimatePoseSingleMarkers(
                corners, self.marker_length, 
                camera_config['camera_matrix'], 
                camera_config['dist_coeffs']
            )
        except Exception as e:
            self.get_logger().error(f"{camera_name} pose estimation failed: {e}")
            return

        # ê²€ì¶œëœ ë§ˆì»¤ ì •ë¦¬
        detected_markers = {}
        for i, marker_id in enumerate(ids.flatten()):
            detected_markers[marker_id] = {
                'cam_tvec': tvecs[i].reshape(3),
                'cam_rvec': rvecs[i].reshape(3),
                'corners': corners[i],
                'camera_name': camera_name  # ğŸ†• ì¹´ë©”ë¼ ì •ë³´ ì¶”ê°€
            }

        # ğŸ†• í•´ë‹¹ ì¹´ë©”ë¼ì˜ ì›”ë“œ ì¢Œí‘œê³„ ì„¤ì •
        self.establish_world_coordinate_system(detected_markers, camera_config, camera_name, msg.header.stamp)

        # ğŸ†• ê²€ì¶œ ê²°ê³¼ ì €ì¥
        camera_config['latest_detections'] = detected_markers
        camera_config['detection_timestamp'] = time.time()

        # ì‹œê°í™” (ê° ì¹´ë©”ë¼ë³„)
        self.visualize_results(cv_image, detected_markers, camera_name)

    def establish_world_coordinate_system(self, detected_markers, camera_config, camera_name, timestamp):
        """í†µí•© ì›”ë“œ ì¢Œí‘œê³„ ì„¤ì • (10ë²ˆ ë§ˆì»¤ ê¸°ì¤€)"""
        
        for marker_id, data in detected_markers.items():
            if marker_id == 10:
                rvec = data['cam_rvec']
                tvec = data['cam_tvec']
                
                # í•´ë‹¹ ì¹´ë©”ë¼ì—ì„œì˜ ì›”ë“œ ì¢Œí‘œê³„ ì„¤ì •
                H_cam2world = np.eye(4)
                R_matrix, _ = cv2.Rodrigues(rvec)
                H_cam2world[0:3, 0:3] = R_matrix
                H_cam2world[0:3, 3] = tvec
                
                H_world2cam = np.linalg.inv(H_cam2world)
                camera_config['H_world2cam'] = H_world2cam
                
                # ğŸ”§ í†µí•©ëœ ì›”ë“œ ì¢Œí‘œê³„ ì„¤ì • (ì²« ë²ˆì§¸ ê²€ì¶œ ì¹´ë©”ë¼ ê¸°ì¤€)
                if not self.world_established:
                    self.H_world2cam_global = H_world2cam
                    self.world_established = True
                    # ğŸŒ í•˜ë‚˜ì˜ ì›”ë“œ í”„ë ˆì„ ë¸Œë¡œë“œìºìŠ¤íŠ¸
                    self.broadcast_world_transform(H_world2cam, timestamp, camera_name)
                    self.get_logger().info(f"âœ… Unified world coordinate system established by {camera_name}")
                
                break

    def fuse_multi_camera_data(self):
        """ë‹¤ì¤‘ ì¹´ë©”ë¼ ë°ì´í„° ìœµí•©"""
        
        if not self.world_established:
            return
        
        # ğŸ†• ëª¨ë“  ì¹´ë©”ë¼ì—ì„œ ê²€ì¶œëœ ë¡œë´‡ ë§ˆì»¤ë“¤ ìˆ˜ì§‘
        all_robot_markers = {}
        current_time = time.time()
        
        for camera_name, camera_config in self.cameras.items():
            # ìµœê·¼ ê²€ì¶œ ë°ì´í„°ë§Œ ì‚¬ìš© (1ì´ˆ ì´ë‚´)
            if (camera_config['detection_timestamp'] is not None and 
                current_time - camera_config['detection_timestamp'] < 1.0 and
                camera_config['H_world2cam'] is not None):
                
                detections = camera_config['latest_detections']
                
                for marker_id, data in detections.items():
                    if marker_id in self.robot_markers_local:
                        # í•´ë‹¹ ì¹´ë©”ë¼ ì¢Œí‘œê³„ â†’ ì›”ë“œ ì¢Œí‘œê³„ ë³€í™˜
                        world_position = self.transform_to_world_coordinates(
                            data['cam_tvec'], 
                            camera_config['H_world2cam']
                        )
                        
                        if world_position is not None:
                            # ê°™ì€ ë§ˆì»¤ê°€ ì—¬ëŸ¬ ì¹´ë©”ë¼ì—ì„œ ê²€ì¶œëœ ê²½ìš° í‰ê·  ì‚¬ìš©
                            if marker_id in all_robot_markers:
                                # ê¸°ì¡´ ìœ„ì¹˜ì™€ í‰ê· 
                                existing_pos = all_robot_markers[marker_id]['world_position']
                                count = all_robot_markers[marker_id]['count']
                                new_pos = (existing_pos * count + world_position) / (count + 1)
                                all_robot_markers[marker_id]['world_position'] = new_pos
                                all_robot_markers[marker_id]['count'] += 1
                                all_robot_markers[marker_id]['cameras'].append(camera_name)
                            else:
                                all_robot_markers[marker_id] = {
                                    'world_position': world_position,
                                    'cam_tvec': data['cam_tvec'], 
                                    'cam_rvec': data['cam_rvec'],
                                    'camera_name': camera_name,
                                    'cameras': [camera_name],
                                    'count': 1
                                }

        # ğŸ¤– ìœµí•©ëœ ë¡œë´‡ ì¤‘ì‹¬ ê³„ì‚°
        if len(all_robot_markers) > 0:
            self.calculate_fused_robot_center(all_robot_markers)

    def transform_to_world_coordinates(self, cam_position, H_world2cam):
        """ì¹´ë©”ë¼ ì¢Œí‘œ â†’ ì›”ë“œ ì¢Œí‘œ ë³€í™˜"""
        try:
            H_cam2world = np.linalg.inv(H_world2cam)
            cam_homo = np.append(cam_position, 1)
            world_homo = H_cam2world @ cam_homo
            return world_homo[:3]
        except Exception:
            return None

    def calculate_fused_robot_center(self, all_robot_markers):
        """ìœµí•©ëœ ë¡œë´‡ ì¤‘ì‹¬ ê³„ì‚°"""
        
        # ì›”ë“œ ì¢Œí‘œê³„ì—ì„œì˜ ë¡œë´‡ ë§ˆì»¤ ìœ„ì¹˜ë“¤
        world_positions = [data['world_position'] for data in all_robot_markers.values()]
        robot_center_world = np.mean(world_positions, axis=0)
        
        # ë¡œë´‡ íšŒì „ ê³„ì‚° (ì²« ë²ˆì§¸ ì¹´ë©”ë¼ì˜ ë°ì´í„° ì‚¬ìš© - ë‹¨ìˆœí™”)
        first_marker_data = list(all_robot_markers.values())[0]
        first_camera_name = first_marker_data['camera_name']
        
        # í•´ë‹¹ ì¹´ë©”ë¼ì—ì„œì˜ íšŒì „ í–‰ë ¬ë“¤ ì‚¬ìš©
        robot_markers_cam = {}
        for marker_id, data in all_robot_markers.items():
            if data['camera_name'] == first_camera_name:
                R_matrix, _ = cv2.Rodrigues(data['cam_rvec'])
                robot_markers_cam[marker_id] = {
                    'position': data['cam_tvec'],
                    'rotation': R_matrix
                }
        
        if len(robot_markers_cam) > 0:
            robot_rotation_cam = self.calculate_robot_rotation_simple(robot_markers_cam)
            
            # H_world2robot ê³„ì‚°
            H_world2robot = np.eye(4)
            H_world2robot[0:3, 0:3] = robot_rotation_cam
            H_world2robot[0:3, 3] = robot_center_world
            self.H_world2robot = H_world2robot
            
            # TF ë¸Œë¡œë“œìºìŠ¤íŠ¸
            timestamp = self.get_clock().now().to_msg()
            self.broadcast_robot_transform(H_world2robot, timestamp)
            
            # ìƒíƒœ ì—…ë°ì´íŠ¸
            self.latest_robot_center = robot_center_world
            self.center_timestamp = time.time()
            
            # ë¡œê·¸
            camera_names = set()
            for data in all_robot_markers.values():
                camera_names.update(data['cameras'])
            
            self.get_logger().info(
                f"ğŸ¤– Fused robot center from {len(all_robot_markers)} markers "
                f"across cameras: {list(camera_names)}"
            )
            
            # ë°œí–‰
            self.publish_robot_center(robot_center_world, len(all_robot_markers))

    # ğŸ†• ê¸°ì¡´ í•¨ìˆ˜ë“¤ì„ ê·¸ëŒ€ë¡œ ìœ ì§€ (ì•½ê°„ ìˆ˜ì •)
    def project_world_to_image_simple(self, world_point, camera_name=None):
        """ì›”ë“œ ì¢Œí‘œë¥¼ íŠ¹ì • ì¹´ë©”ë¼ì˜ ì´ë¯¸ì§€ë¡œ íˆ¬ì˜"""
        
        if camera_name is None:
            # ì²« ë²ˆì§¸ ì¹´ë©”ë¼ ì‚¬ìš©
            camera_name = list(self.cameras.keys())[0]
        
        camera_config = self.cameras[camera_name]
        H_world2cam = camera_config.get('H_world2cam')
        
        if H_world2cam is None:
            return None
        
        try:
            # ì›”ë“œ â†’ ì¹´ë©”ë¼ ë³€í™˜
            world_point_homogeneous = np.append(world_point, 1)
            cam_point_homogeneous = H_world2cam @ world_point_homogeneous
            cam_point = cam_point_homogeneous[:3]
            
            if cam_point[2] <= 0:  # ì¹´ë©”ë¼ ë’¤ì— ìˆìŒ
                return None
            
            # ì¹´ë©”ë¼ â†’ ì´ë¯¸ì§€ íˆ¬ì˜
            image_points, _ = cv2.projectPoints(
                cam_point.reshape(1, 1, 3), np.zeros(3), np.zeros(3),
                camera_config['camera_matrix'], camera_config['dist_coeffs']
            )
            
            return image_points[0][0]
            
        except Exception as e:
            return None

    def publish_robot_center(self, center, num_markers):
        """ë¡œë´‡ ì¤‘ì‹¬ ìœ„ì¹˜ ë°œí–‰"""
        msg = PoseStamped()
        msg.header = Header()
        msg.header.stamp = self.get_clock().now().to_msg()
        msg.header.frame_id = 'world'  # ğŸŒ í†µí•©ëœ ì›”ë“œ í”„ë ˆì„ ì‚¬ìš©
        
        msg.pose.position.x = float(center[0])
        msg.pose.position.y = float(center[1])
        msg.pose.position.z = float(center[2])
        msg.pose.orientation.w = 1.0
        
        self.robot_center_pub.publish(msg)

    def broadcast_robot_transform(self, H_world2robot, timestamp):
        """ë¡œë´‡ ì¢Œí‘œê³„ tf ë¸Œë¡œë“œìºìŠ¤íŠ¸ (í†µí•© ì›”ë“œ í”„ë ˆì„ ê¸°ì¤€)"""
        try:
            t = TransformStamped()
            t.header.stamp = timestamp
            t.header.frame_id = 'world'  # ğŸŒ í†µí•©ëœ ì›”ë“œ í”„ë ˆì„ ì‚¬ìš©
            t.child_frame_id = 'robot_center'
            
            # ìœ„ì¹˜
            t.transform.translation.x = float(H_world2robot[0, 3])
            t.transform.translation.y = float(H_world2robot[1, 3])
            t.transform.translation.z = float(H_world2robot[2, 3])
            
            # íšŒì „
            R_mat = H_world2robot[0:3, 0:3]
            rot = R.from_matrix(R_mat)
            quat = rot.as_quat()  # [x, y, z, w]
            t.transform.rotation.x = quat[0]
            t.transform.rotation.y = quat[1]
            t.transform.rotation.z = quat[2]
            t.transform.rotation.w = quat[3]
            
            self.tf_broadcaster.sendTransform(t)
            
        except Exception as e:
            self.get_logger().warn(f"Robot transform broadcast failed: {e}")

    def broadcast_world_transform(self, H_world2cam, timestamp, camera_name):
        """í†µí•©ëœ ì›”ë“œ ì¢Œí‘œê³„ tf ë¸Œë¡œë“œìºìŠ¤íŠ¸ (í•˜ë‚˜ì˜ world í”„ë ˆì„)"""
        try:
            H_cam2world = np.linalg.inv(H_world2cam)
            
            t = TransformStamped()
            t.header.stamp = timestamp
            t.header.frame_id = f'{camera_name}_link'  # ê¸°ì¤€ ì¹´ë©”ë¼ í”„ë ˆì„
            t.child_frame_id = 'world'  # ğŸŒ í†µí•©ëœ í•˜ë‚˜ì˜ ì›”ë“œ í”„ë ˆì„
            
            # ìœ„ì¹˜
            t.transform.translation.x = float(H_cam2world[0, 3])
            t.transform.translation.y = float(H_cam2world[1, 3])
            t.transform.translation.z = float(H_cam2world[2, 3])
            
            # íšŒì „
            R_mat = H_cam2world[0:3, 0:3]
            rot = R.from_matrix(R_mat)
            quat = rot.as_quat()
            t.transform.rotation.x = quat[0]
            t.transform.rotation.y = quat[1]
            t.transform.rotation.z = quat[2]
            t.transform.rotation.w = quat[3]
            
            self.tf_broadcaster.sendTransform(t)
            
            self.get_logger().info(f"ğŸŒ Unified world frame established from {camera_name}_link")
            
        except Exception as e:
            self.get_logger().warn(f"World transform broadcast failed for {camera_name}: {e}")

    def calculate_robot_rotation_simple(self, robot_markers_cam):
        """ê°„ë‹¨í•œ ì•„ì›ƒë¼ì´ì–´ ì œê±° + íšŒì „ í‰ê·  (ê¸°ì¡´ê³¼ ë™ì¼)"""
        
        if len(robot_markers_cam) <= 1:
            return list(robot_markers_cam.values())[0]['rotation']
        
        from scipy.spatial.transform import Rotation as R_scipy
        
        rotations_data = []
        for marker_id, data in robot_markers_cam.items():
            rot_matrix = data['rotation']
            r = R_scipy.from_matrix(rot_matrix)
            quat = r.as_quat()
            rotations_data.append((marker_id, quat, rot_matrix))
        
        reference_quat = rotations_data[0][1]
        valid_rotations = []
        
        for marker_id, quat, rot_matrix in rotations_data:
            dot_product = np.abs(np.dot(reference_quat, quat))
            angle_diff = 2 * np.arccos(np.clip(dot_product, 0, 1))
            
            if angle_diff <= 0.5:  # ì•½ 30ë„ ì´ë‚´
                valid_rotations.append(quat)
            else:
                self.get_logger().warn(f"âš ï¸ Marker {marker_id} removed: angle diff {np.degrees(angle_diff):.1f}Â°")
        
        if len(valid_rotations) > 0:
            mean_quat = np.mean(valid_rotations, axis=0)
            mean_quat = mean_quat / np.linalg.norm(mean_quat)
            return R_scipy.from_quat(mean_quat).as_matrix()
        else:
            return rotations_data[0][2]
    
    def visualize_results(self, image, detected_markers, camera_name):
        """ê²€ì¶œ ê²°ê³¼ ì‹œê°í™” (ì¹´ë©”ë¼ë³„)"""
        
        # ê²€ì¶œëœ ë§ˆì»¤ë“¤ í‘œì‹œ
        for marker_id, data in detected_markers.items():
            corners = data['corners'][0]
            center = np.mean(corners, axis=0).astype(int)
            
            if marker_id == 10:
                # 10ë²ˆ ë§ˆì»¤ - ì›”ë“œ ì›ì 
                color = (255, 0, 0)
                label = f"World{marker_id}"
                cv2.polylines(image, [corners.astype(int)], True, (0, 255, 0), 2)
                cv2.putText(image, label, tuple(center), 
                        cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)
                self.draw_coordinate_axes(image, data['cam_rvec'], data['cam_tvec'], 0.05, camera_name)

        # ìƒíƒœ ì •ë³´ í‘œì‹œ
        world_status = "World: OK" if self.world_established else "World: No Marker 10"
        world_color = (0, 255, 0) if self.world_established else (0, 0, 255)
        cv2.putText(image, f"{camera_name} - {world_status}", (10, 30), 
                cv2.FONT_HERSHEY_SIMPLEX, 0.7, world_color, 2)
        
        # ë¡œë´‡ ì¢Œí‘œ í‘œì‹œ
        if self.latest_robot_center is not None:
            coord_text = f"Robot: ({self.latest_robot_center[0]:.2f}, {self.latest_robot_center[1]:.2f}, {self.latest_robot_center[2]:.2f})"
            cv2.putText(image, coord_text, (10, 60), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)

        # ğŸ†• ì¹´ë©”ë¼ë³„ ì°½ í‘œì‹œ
        cv2.imshow(f'{camera_name} - ArUco Detection', image)
        cv2.waitKey(1)

    def draw_coordinate_axes(self, image, rvec, tvec, length, camera_name):
        """ì¢Œí‘œì¶• ê·¸ë¦¬ê¸° (ì¹´ë©”ë¼ë³„)"""
        camera_config = self.cameras[camera_name]
        
        try:
            axis_points = np.float32([[0,0,0], [length,0,0], [0,length,0], [0,0,length]]).reshape(-1,3)
            
            imgpts, _ = cv2.projectPoints(axis_points, rvec, tvec, 
                                        camera_config['camera_matrix'], 
                                        camera_config['dist_coeffs'])
            
            imgpts = np.int32(imgpts).reshape(-1,2)
            origin = tuple(imgpts[0])
            
            # Xì¶• (ë¹¨ê°„ìƒ‰), Yì¶• (ì´ˆë¡ìƒ‰), Zì¶• (íŒŒë€ìƒ‰)
            cv2.arrowedLine(image, origin, tuple(imgpts[1]), (0,0,255), 2)
            cv2.arrowedLine(image, origin, tuple(imgpts[2]), (0,255,0), 2)
            cv2.arrowedLine(image, origin, tuple(imgpts[3]), (255,0,0), 2)
            
        except Exception:
            pass

def main(args=None):
    rclpy.init(args=args)
    detector = D435MultiCameraArucoDetector()
    
    try:
        rclpy.spin(detector)
    except KeyboardInterrupt:
        pass
    finally:
        cv2.destroyAllWindows()
        detector.destroy_node()
        rclpy.shutdown()

if __name__ == '__main__':
    main()