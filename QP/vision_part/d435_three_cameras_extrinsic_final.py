#!/usr/bin/env python3

import numpy as np
import cv2
import cv2.aruco as aruco
import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image, CameraInfo
from geometry_msgs.msg import PoseStamped, TransformStamped
from std_msgs.msg import Header
from cv_bridge import CvBridge
import time
import tf2_ros
from scipy.spatial.transform import Rotation as R
import yaml
import os
import rclpy.time
import rclpy.duration

class D435ArucoDetectorWithExtrinsic(Node):
    def __init__(self):
        super().__init__('d435_aruco_detector_extrinsic')
        
        # ë¡œë´‡ ë§ˆì»¤ë“¤ (0~3ë²ˆ) - ë¡œì»¬ ì¢Œí‘œê³„
        self.robot_markers_local = {
            0: np.array([0.2875, 0.1225, 0.0]),
            1: np.array([0.2875, -0.1225, 0.0]),
            2: np.array([-0.2875, -0.1225, 0.0]),
            3: np.array([-0.2875, 0.1225, 0.0])
        }
    
        self.marker_length = 0.075  # ë§ˆì»¤ í¬ê¸°
        
        # ì›”ë“œ ì¢Œí‘œê³„ ì„¤ì • ìƒíƒœ
        self.world_established = False
        self.world_from_marker = False  # ë§ˆì»¤ë¡œë¶€í„° ì„¤ì •ë˜ì—ˆëŠ”ì§€ ì—¬ë¶€
        self.world_from_extrinsic = False  # extrinsicìœ¼ë¡œë¶€í„° ì„¤ì •ë˜ì—ˆëŠ”ì§€ ì—¬ë¶€
        
        # ğŸ†• Extrinsic calibration ë°ì´í„°
        self.extrinsic_data = {}
        self.load_extrinsic_calibration()
        
        # ì¹´ë©”ë¼ë³„ ì •ë³´ ì €ì¥
        self.cameras = {
            'camera1': {
                'frame_id': 'camera1_color_optical_frame',
                'camera_matrix': None,
                'dist_coeffs': None,
                'info_received': False,
                'H_world2cam': None,
                'latest_detections': {},
                'detection_timestamp': None
            },
            'camera2': {
                'frame_id': 'camera2_color_optical_frame', 
                'camera_matrix': None,
                'dist_coeffs': None,
                'info_received': False,
                'H_world2cam': None,
                'latest_detections': {},
                'detection_timestamp': None
            },
            'camera3': {
                'frame_id': 'camera3_color_optical_frame',
                'camera_matrix': None,
                'dist_coeffs': None, 
                'info_received': False,
                'H_world2cam': None,
                'latest_detections': {},
                'detection_timestamp': None
            }
        }
        
        # ë¡œë´‡ ì¤‘ì‹¬ ì¶”ì 
        self.latest_robot_center = None
        self.center_timestamp = None

        # ArUco ì„¤ì •
        self.aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_4X4_50)
        self.aruco_params = cv2.aruco.DetectorParameters()

        # ë³€í™˜ í–‰ë ¬ë“¤
        self.H_cam2robot = None
        self.H_world2robot = None
        
        # ì›”ë“œ ê¸°ì¤€ ì¹´ë©”ë¼ ê´€ë ¨
        self.world_reference_camera = None
        
        self.tf_broadcaster = tf2_ros.TransformBroadcaster(self)
        
        # ğŸ†• TF ë¦¬ìŠ¤ë„ˆ ì¶”ê°€ (ê²€ì¦ìš©)
        self.tf_buffer = tf2_ros.Buffer()
        self.tf_listener = tf2_ros.TransformListener(self.tf_buffer, self)

        # ğŸ†• ê° ì¹´ë©”ë¼ë³„ êµ¬ë…ì ì„¤ì •
        self.setup_camera_subscriptions()
        
        # ë°œí–‰ì
        self.robot_center_pub = self.create_publisher(
            PoseStamped, '/robot_center', 10
        )
        
        # ğŸ†• ì£¼ê¸°ì ìœ¼ë¡œ extrinsic ê¸°ë°˜ TF ë¸Œë¡œë“œìºìŠ¤íŠ¸
        self.create_timer(0.1, self.broadcast_extrinsic_transforms)  # 10Hz
        
        # ğŸ†• Extrinsic vs TF ë¹„êµ ê²€ì¦ (5ì´ˆë§ˆë‹¤)
        self.create_timer(0.5, self.validate_extrinsic_vs_tf)  # 0.2Hz
        self.validation_results = {}
        
        self.get_logger().info("D435 ArUco Detector with Extrinsic Support initialized")

    def load_extrinsic_calibration(self):
        """Extrinsic calibration ë°ì´í„° ë¡œë“œ"""
        try:
            # í†µí•© íŒŒì¼ ì‹œë„
            if os.path.exists('multi_camera_calibration.yaml'):
                with open('multi_camera_calibration.yaml', 'r') as f:
                    data = yaml.safe_load(f)
                
                if 'cameras' in data:
                    for camera_name, camera_data in data['cameras'].items():
                        position = np.array(camera_data['position'])
                        rotation = np.array(camera_data['rotation_matrix'])
                        
                        # ğŸ”§ ì˜¬ë°”ë¥¸ ì›”ë“œ â†’ ì¹´ë©”ë¼ ë³€í™˜ í–‰ë ¬ êµ¬ì„±
                        # Extrinsic calibrationì—ì„œ position, rotationì€ ì›”ë“œì—ì„œ ì¹´ë©”ë¼ì˜ ìœ„ì¹˜/ìì„¸
                        # ë”°ë¼ì„œ H_cam2worldë¥¼ ë¨¼ì € ë§Œë“¤ê³  ì—­ë³€í™˜
                        H_cam2world = np.eye(4)
                        H_cam2world[0:3, 0:3] = rotation
                        H_cam2world[0:3, 3] = position
                        
                        H_world2cam = np.linalg.inv(H_cam2world)
                        
                        self.extrinsic_data[camera_name] = {
                            'position': position,
                            'rotation': rotation,
                            'H_world2cam': H_world2cam
                        }
                        
                        self.get_logger().info(f"ğŸ“‹ Loaded extrinsic data for {camera_name}")
                
                if len(self.extrinsic_data) > 0:
                    self.get_logger().info(f"âœ… Loaded extrinsic calibration for {len(self.extrinsic_data)} cameras")
                    # extrinsic ë°ì´í„°ë¡œ ì›”ë“œ ì¢Œí‘œê³„ ì„¤ì •
                    self.setup_world_from_extrinsic()
                else:
                    self.get_logger().warn("âš ï¸ No camera data found in multi_camera_calibration.yaml")
                    
        except Exception as e:
            self.get_logger().warn(f"âš ï¸ Could not load extrinsic calibration: {e}")
            self.get_logger().info("Will use marker-based calibration when available")

    def setup_world_from_extrinsic(self):
        """Extrinsic ë°ì´í„°ë¥¼ ì‚¬ìš©í•´ì„œ ì›”ë“œ ì¢Œí‘œê³„ ì„¤ì •"""
        if len(self.extrinsic_data) > 0:
            self.world_established = True
            self.world_from_extrinsic = True
            
            # ê° ì¹´ë©”ë¼ì˜ H_world2cam ì„¤ì •
            for camera_name, extrinsic in self.extrinsic_data.items():
                if camera_name in ['camera1', 'camera2', 'camera3']:
                    self.cameras[camera_name]['H_world2cam'] = extrinsic['H_world2cam']
            
            self.get_logger().info("ğŸŒ World coordinate system established from extrinsic calibration")

    def setup_camera_subscriptions(self):
        """ê° ì¹´ë©”ë¼ë³„ êµ¬ë…ì ì„¤ì • - í´ë¡œì € ë¬¸ì œ í•´ê²°"""
        
        def make_image_callback(camera_name):
            """í´ë¡œì € ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ì½œë°± ìƒì„± í•¨ìˆ˜"""
            return lambda msg: self.image_callback(msg, camera_name)
        
        def make_info_callback(camera_name):
            """í´ë¡œì € ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ì •ë³´ ì½œë°± ìƒì„± í•¨ìˆ˜"""
            return lambda msg: self.camera_info_callback(msg, camera_name)
        
        for camera_name in self.cameras.keys():
            # ì´ë¯¸ì§€ êµ¬ë… - ê°œë³„ ì½œë°± í•¨ìˆ˜ ìƒì„±
            self.create_subscription(
                Image, 
                f'/{camera_name}/{camera_name}/color/image_raw', 
                make_image_callback(camera_name), 
                10
            )
            
            # ì¹´ë©”ë¼ ì •ë³´ êµ¬ë… - ê°œë³„ ì½œë°± í•¨ìˆ˜ ìƒì„±
            self.create_subscription(
                CameraInfo, 
                f'/{camera_name}/{camera_name}/color/camera_info',
                make_info_callback(camera_name), 
                10
            )
            
            self.get_logger().info(f"ğŸ“· Subscribed to {camera_name}")

    def camera_info_callback(self, msg, camera_name):
        """ì¹´ë©”ë¼ ë‚´ë¶€ ë§¤ê°œë³€ìˆ˜ ìˆ˜ì‹ """
        camera_config = self.cameras[camera_name]
        
        if not camera_config['info_received']:
            camera_config['camera_matrix'] = np.array(msg.k).reshape(3, 3)
            camera_config['dist_coeffs'] = np.array(msg.d)
            camera_config['info_received'] = True
            self.get_logger().info(f"ğŸ“· {camera_name} intrinsics received")

    def image_callback(self, msg, camera_name):
        """ê° ì¹´ë©”ë¼ë³„ ì´ë¯¸ì§€ ì²˜ë¦¬ ë° ArUco ê²€ì¶œ"""
        
        # ğŸ”§ ì¹´ë©”ë¼ ì´ë¦„ ê²€ì¦
        if camera_name not in self.cameras:
            self.get_logger().warn(f"âŒ Unknown camera name: {camera_name}")
            return
            
        camera_config = self.cameras[camera_name]
        
        if not camera_config['info_received']:
            return
            
        bridge = CvBridge()
        cv_image = bridge.imgmsg_to_cv2(msg, desired_encoding='bgr8')
        gray = cv2.cvtColor(cv_image, cv2.COLOR_BGR2GRAY)

        # ArUco ë§ˆì»¤ ê²€ì¶œ
        detector = aruco.ArucoDetector(self.aruco_dict, self.aruco_params)
        corners, ids, _ = detector.detectMarkers(gray)

        if ids is None:
            # ê²€ì¶œ ì‹¤íŒ¨ì‹œ íƒ€ì„ìŠ¤íƒ¬í”„ë§Œ ì—…ë°ì´íŠ¸
            camera_config['latest_detections'] = {}
            camera_config['detection_timestamp'] = time.time()
            self.visualize_results(cv_image, {}, camera_name)
            return

        # í¬ì¦ˆ ì¶”ì • (í•´ë‹¹ ì¹´ë©”ë¼ ì¢Œí‘œê³„)
        try:
            rvecs, tvecs, _ = cv2.aruco.estimatePoseSingleMarkers(
                corners, self.marker_length, 
                camera_config['camera_matrix'], 
                camera_config['dist_coeffs']
            )
        except Exception as e:
            self.get_logger().error(f"{camera_name} pose estimation failed: {e}")
            return

        # ê²€ì¶œëœ ë§ˆì»¤ ì •ë¦¬
        detected_markers = {}
        for i, marker_id in enumerate(ids.flatten()):
            detected_markers[marker_id] = {
                'cam_tvec': tvecs[i].reshape(3),
                'cam_rvec': rvecs[i].reshape(3),
                'corners': corners[i],
                'camera_name': camera_name
            }

        # ğŸ†• 10ë²ˆ ë§ˆì»¤ ê¸°ë°˜ ì›”ë“œ ì¢Œí‘œê³„ ì—…ë°ì´íŠ¸ (ìš°ì„ ìˆœìœ„)
        self.update_world_from_marker(detected_markers, camera_config, camera_name, msg.header.stamp)

        # ğŸ†• ê²€ì¶œ ê²°ê³¼ ì €ì¥
        camera_config['latest_detections'] = detected_markers
        camera_config['detection_timestamp'] = time.time()

        # ğŸ¤– ë¡œë´‡ ì¤‘ì‹¬ ê³„ì‚°
        self.calculate_robot_center(detected_markers, camera_config, camera_name, msg.header.stamp)

        # ì‹œê°í™”
        self.visualize_results(cv_image, detected_markers, camera_name)

    def update_world_from_marker(self, detected_markers, camera_config, camera_name, timestamp):
        """10ë²ˆ ë§ˆì»¤ë¥¼ ë°œê²¬í–ˆì„ ë•Œ ì›”ë“œ ì¢Œí‘œê³„ ì—…ë°ì´íŠ¸ (ìµœê³  ìš°ì„ ìˆœìœ„)"""
        
        for marker_id, data in detected_markers.items():
            if marker_id == 10:
                rvec = data['cam_rvec']
                tvec = data['cam_tvec']
                
                # ë§ˆì»¤ ê¸°ì¤€ ì›”ë“œ ì¢Œí‘œê³„ ê³„ì‚°
                H_cam2world = np.eye(4)
                R_matrix, _ = cv2.Rodrigues(rvec)
                H_cam2world[0:3, 0:3] = R_matrix
                H_cam2world[0:3, 3] = tvec
                
                H_world2cam = np.linalg.inv(H_cam2world)
                camera_config['H_world2cam'] = H_world2cam
                
                # ğŸ”§ ì¹´ë©”ë¼ TFëŠ” íƒ€ì´ë¨¸ì—ì„œ ì²˜ë¦¬ (ì¤‘ë³µ ë°©ì§€)
                
                # ì²« ë²ˆì§¸ ë§ˆì»¤ ê¸°ë°˜ ì›”ë“œ ì„¤ì •
                if not self.world_from_marker:
                    self.world_established = True
                    self.world_from_marker = True
                    self.world_reference_camera = camera_name
                    
                    # ê¸°ì¡´ extrinsic ê¸°ë°˜ ì„¤ì • ë¬´íš¨í™”
                    if self.world_from_extrinsic:
                        self.get_logger().info("ğŸ”„ Switching from extrinsic to marker-based world coordinate system")
                        self.world_from_extrinsic = False
                    
                    self.get_logger().info(f"âœ… Marker-based world coordinate system established by {camera_name}")
                
                break

    def calculate_robot_center(self, detected_markers, camera_config, camera_name, timestamp):
        """ë¡œë´‡ ì¤‘ì‹¬ ê³„ì‚°"""
        
        if not self.world_established:
            return
            
        # ë¡œë´‡ ë§ˆì»¤ë“¤ ìˆ˜ì§‘
        robot_markers_cam = {}
        for marker_id, data in detected_markers.items():
            if marker_id in self.robot_markers_local:
                rvec = data['cam_rvec']
                tvec = data['cam_tvec']
                R_matrix, _ = cv2.Rodrigues(rvec)
                robot_markers_cam[marker_id] = {
                    'position': tvec,
                    'rotation': R_matrix
                }

        if len(robot_markers_cam) > 0:
            # í•˜ë‚˜ì˜ ë§ˆì»¤ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë¡œë´‡ ì¤‘ì‹¬ ê³„ì‚°
            robot_center_cam, robot_rotation_cam = self.calculate_robot_center_from_single_marker(robot_markers_cam)
            
            # H_cam2robot
            H_cam2robot = np.eye(4)
            H_cam2robot[0:3, 0:3] = robot_rotation_cam
            H_cam2robot[0:3, 3] = robot_center_cam
            self.H_cam2robot = H_cam2robot
            
            # ì›”ë“œ ì¢Œí‘œê³„ë¡œ ë³€í™˜ - ì›ë³¸ê³¼ ë™ì¼í•˜ê²Œ
            H_world2cam = camera_config['H_world2cam']
            if H_world2cam is not None:
                H_world2robot = H_world2cam @ H_cam2robot
                robot_center_world = H_world2robot[:3, 3]
                
                # ğŸ”§ ì›ë³¸ê³¼ ë™ì¼í•˜ê²Œ timestampì™€ camera_name ì „ë‹¬
                self.broadcast_robot_transform(H_world2robot, camera_name, timestamp)
                self.latest_robot_center = robot_center_world
                self.center_timestamp = time.time()
                
                self.get_logger().info(f"ğŸ¤– Robot center (cam): {robot_center_cam}")
                self.get_logger().info(f"ğŸŒ Robot center (world): {robot_center_world}")
                self.publish_robot_center(robot_center_world, H_world2robot)

    def calculate_robot_center_from_single_marker(self, robot_markers_cam):
        """í•˜ë‚˜ì˜ ë§ˆì»¤ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë¡œì»¬ ì¢Œí‘œê³„ ì˜¤í”„ì…‹ì„ ì´ìš©í•´ ë¡œë´‡ ì¤‘ì‹¬ ê³„ì‚°"""
        
        # ê°€ì¥ ì‹ ë¢°í• ë§Œí•œ ë§ˆì»¤ ì„ íƒ
        best_marker_id = min(robot_markers_cam.keys())
        best_marker_data = robot_markers_cam[best_marker_id]
        
        marker_position_cam = best_marker_data['position']
        marker_rotation_cam = best_marker_data['rotation']
        
        # ë¡œì»¬ ì¢Œí‘œê³„ì—ì„œì˜ ì˜¤í”„ì…‹
        marker_offset_local = self.robot_markers_local[best_marker_id]
        
        # ë¡œì»¬ ì˜¤í”„ì…‹ì„ ì¹´ë©”ë¼ ì¢Œí‘œê³„ë¡œ ë³€í™˜
        marker_offset_cam = marker_rotation_cam @ marker_offset_local
        
        # ë¡œë´‡ ì¤‘ì‹¬ = ë§ˆì»¤ ìœ„ì¹˜ - ë§ˆì»¤ ì˜¤í”„ì…‹
        robot_center_cam = marker_position_cam - marker_offset_cam
        
        return robot_center_cam, marker_rotation_cam

    def broadcast_extrinsic_transforms(self):
        """ğŸ”§ ì•ˆì •ì ì¸ TF ë¸Œë¡œë“œìºìŠ¤íŠ¸ - íƒ€ì„ìŠ¤íƒ¬í”„ í†µì¼"""
        
        if not self.world_established:
            return
        
        # ğŸ”§ íƒ€ì„ìŠ¤íƒ¬í”„ í†µì¼
        timestamp = self.get_clock().now().to_msg()
        
        # ğŸ”§ ë””ë²„ê¹…ìš© ìƒíƒœ í™•ì¸
        current_time = time.time()
        active_cameras = []
        
        # ëª¨ë“  ì¹´ë©”ë¼ì— ëŒ€í•´ TF ë¸Œë¡œë“œìºìŠ¤íŠ¸
        for camera_name in ['camera1', 'camera2', 'camera3']:
            camera_config = self.cameras[camera_name]
            
            # ì¹´ë©”ë¼ë³„ ìƒíƒœ ì²´í¬
            detection_age = float('inf')
            if camera_config.get('detection_timestamp'):
                detection_age = current_time - camera_config['detection_timestamp']
            
            # ìš°ì„ ìˆœìœ„ 1: ë§ˆì»¤ ê¸°ë°˜ ë°ì´í„° (ì‹¤ì‹œê°„) - ìµœê·¼ ë°ì´í„°ë§Œ ì‚¬ìš©
            if (camera_config['H_world2cam'] is not None and 
                self.world_from_marker and 
                camera_config.get('detection_timestamp') is not None and
                detection_age < 0.3):  # ğŸ”§ 0.3ì´ˆë¡œ ì—„ê²©í•˜ê²Œ
                
                # ğŸ”§ ìœ íš¨ì„± ê²€ì‚¬
                H_world2cam = camera_config['H_world2cam']
                if not np.any(np.isnan(H_world2cam)) and not np.any(np.isinf(H_world2cam)):
                    self.broadcast_camera_transform_from_marker(
                        camera_name, 
                        H_world2cam, 
                        timestamp
                    )
                    active_cameras.append(f"{camera_name}(M)")
                else:
                    self.get_logger().warn(f"âš ï¸ Invalid H_world2cam for {camera_name}")
            
            # ìš°ì„ ìˆœìœ„ 2: Extrinsic ë°ì´í„° (ë°±ì—…) - ì•ˆì •ì 
            elif camera_name in self.extrinsic_data and self.world_from_extrinsic:
                self.broadcast_camera_transform_from_extrinsic(
                    camera_name, 
                    None, None,  # ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
                    timestamp
                )
                active_cameras.append(f"{camera_name}(E)")
        
        # ğŸ”§ ì£¼ê¸°ì  ìƒíƒœ ë¡œê¹… (5ì´ˆë§ˆë‹¤)
        if not hasattr(self, 'last_status_log'):
            self.last_status_log = 0
        
        if current_time - self.last_status_log > 5.0:
            self.get_logger().info(f"ğŸ“Š Active cameras: {', '.join(active_cameras) if active_cameras else 'None'}")
            self.last_status_log = current_time

    def broadcast_camera_transform_from_extrinsic(self, camera_name, position, rotation, timestamp):
        """Extrinsic ë°ì´í„°ë¥¼ ì‚¬ìš©í•´ì„œ ì¹´ë©”ë¼ TF ë¸Œë¡œë“œìºìŠ¤íŠ¸ - ì˜¬ë°”ë¥¸ ë³€í™˜"""
        
        t = TransformStamped()
        t.header.stamp = timestamp
        t.header.frame_id = 'world'
        t.child_frame_id = f'{camera_name}_frame'
        
        # ğŸ”§ ì˜¬ë°”ë¥¸ ë³€í™˜: H_world2cam ì‚¬ìš© (ë§ˆì»¤ ê¸°ë°˜ê³¼ ë™ì¼í•œ ë°©ì‹)
        H_world2cam = self.extrinsic_data[camera_name]['H_world2cam']
        
        t.transform.translation.x = float(H_world2cam[0, 3])
        t.transform.translation.y = float(H_world2cam[1, 3])
        t.transform.translation.z = float(H_world2cam[2, 3])
        
        R_mat = H_world2cam[0:3, 0:3]
        rot = R.from_matrix(R_mat)
        quat = rot.as_quat()
        t.transform.rotation.x = quat[0]
        t.transform.rotation.y = quat[1]
        t.transform.rotation.z = quat[2]
        t.transform.rotation.w = quat[3]
        
        self.tf_broadcaster.sendTransform(t)

    def broadcast_camera_transform_from_marker(self, camera_name, H_world2cam, timestamp):
        """ë§ˆì»¤ ë°ì´í„°ë¥¼ ì‚¬ìš©í•´ì„œ ì¹´ë©”ë¼ TF ë¸Œë¡œë“œìºìŠ¤íŠ¸ - ì‘ë™í•˜ëŠ” ë²„ì „ê³¼ ë™ì¼í•˜ê²Œ"""
        
        t = TransformStamped()
        t.header.stamp = timestamp  # ğŸ”§ í†µì¼ëœ íƒ€ì„ìŠ¤íƒ¬í”„ ì‚¬ìš©
        t.header.frame_id = 'world'
        t.child_frame_id = f'{camera_name}_frame'
        
        # ğŸ”§ ì‘ë™í•˜ëŠ” ë²„ì „ê³¼ ë™ì¼í•˜ê²Œ: H_world2camì„ ì§ì ‘ ì‚¬ìš©
        t.transform.translation.x = float(H_world2cam[0, 3])
        t.transform.translation.y = float(H_world2cam[1, 3])
        t.transform.translation.z = float(H_world2cam[2, 3])
        
        R_mat = H_world2cam[0:3, 0:3]
        rot = R.from_matrix(R_mat)
        quat = rot.as_quat()
        t.transform.rotation.x = quat[0]
        t.transform.rotation.y = quat[1]
        t.transform.rotation.z = quat[2]
        t.transform.rotation.w = quat[3]
        
        self.tf_broadcaster.sendTransform(t)

    def broadcast_robot_transform(self, H_world2robot, camera_name, timestamp):
        """ë¡œë´‡ ì¢Œí‘œê³„ tf ë¸Œë¡œë“œìºìŠ¤íŠ¸ - ì›ë³¸ê³¼ ë™ì¼"""
        
        t = TransformStamped()
        t.header.stamp = timestamp
        t.header.frame_id = 'world'  # ëª¨ë“  ë¡œë´‡ì€ ê°™ì€ worldë¥¼ ê¸°ì¤€ìœ¼ë¡œ
        t.child_frame_id = 'robot_center'
        
        # ìœ„ì¹˜
        t.transform.translation.x = float(H_world2robot[0, 3])
        t.transform.translation.y = float(H_world2robot[1, 3])
        t.transform.translation.z = float(H_world2robot[2, 3])
        
        # íšŒì „ (H_world2robotì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©)
        R_mat = H_world2robot[0:3, 0:3]
        rot = R.from_matrix(R_mat)
        quat = rot.as_quat()  # [x, y, z, w]
        t.transform.rotation.x = quat[0]
        t.transform.rotation.y = quat[1]
        t.transform.rotation.z = quat[2]
        t.transform.rotation.w = quat[3]
        
        self.tf_broadcaster.sendTransform(t)
        
        self.get_logger().info(f"ğŸ¤– Broadcasting robot_center from world (detected by {camera_name})")

    def validate_extrinsic_vs_tf(self):
        """ğŸ” Extrinsic ë°ì´í„°ì™€ ì‹¤ì œ TF ì¢Œí‘œê³„ ë¹„êµ ê²€ì¦"""
        
        if not self.world_established:
            return
            
        # ì›”ë“œ ê¸°ì¤€ ì¹´ë©”ë¼ê°€ ì„¤ì •ë˜ì–´ ìˆê³ , ë§ˆì»¤ ê¸°ë°˜ ì›”ë“œê°€ í™œì„±í™”ëœ ê²½ìš°ì—ë§Œ ê²€ì¦
        if not self.world_from_marker or self.world_reference_camera is None:
            return
            
        try:
            validation_results = {}
            
            # ê° ì¹´ë©”ë¼ì— ëŒ€í•´ ê²€ì¦
            for camera_name in ['camera1', 'camera2', 'camera3']:
                if camera_name == self.world_reference_camera:
                    continue  # ê¸°ì¤€ ì¹´ë©”ë¼ëŠ” ì œì™¸
                    
                result = self.compare_camera_position(camera_name)
                if result is not None:
                    validation_results[camera_name] = result
            
            # ê²°ê³¼ ì €ì¥ ë° ì¶œë ¥
            if validation_results:
                self.validation_results = validation_results
                self.log_validation_results(validation_results)
                
        except Exception as e:
            self.get_logger().warn(f"âš ï¸ Validation failed: {e}")

    def compare_camera_position(self, target_camera):
        """íŠ¹ì • ì¹´ë©”ë¼ì˜ extrinsic vs TF ìœ„ì¹˜ ë¹„êµ"""
        
        try:
            # 1. í˜„ì¬ TFì—ì„œ ì¹´ë©”ë¼ ìœ„ì¹˜ ê°€ì ¸ì˜¤ê¸°
            tf_transform = self.tf_buffer.lookup_transform(
                'world', f'{target_camera}_frame', 
                rclpy.time.Time(), timeout=rclpy.duration.Duration(seconds=1.0)
            )
            
            # ğŸ”§ TFì—ì„œ ê°€ì ¸ì˜¨ ê²ƒì€ H_world2cam í˜•íƒœì˜ ë³€í™˜
            tf_H_cam2world_translation = np.array([
                tf_transform.transform.translation.x,
                tf_transform.transform.translation.y,
                tf_transform.transform.translation.z
            ])
            
            tf_H_cam2world_rotation = R.from_quat([
                tf_transform.transform.rotation.x,
                tf_transform.transform.rotation.y,
                tf_transform.transform.rotation.z,
                tf_transform.transform.rotation.w
            ]).as_matrix()
            
            # ğŸ”§ ì¹´ë©”ë¼ì˜ ì‹¤ì œ ì›”ë“œ ì¢Œí‘œ ê³„ì‚°: H_cam2world êµ¬ì„±
            tf_H_cam2world = np.eye(4)
            tf_H_cam2world[:3, :3] = tf_H_cam2world_rotation
            tf_H_cam2world[:3, 3] = tf_H_cam2world_translation
            
            tf_H_world2cam = np.linalg.inv(tf_H_cam2world)
            tf_position = tf_H_world2cam[:3, 3]  # ì¹´ë©”ë¼ì˜ ì‹¤ì œ ì›”ë“œ ì¢Œí‘œ
            tf_rotation = tf_H_world2cam[:3, :3]
            
            # 2. Extrinsic ë°ì´í„°ì—ì„œ ì¹´ë©”ë¼ ìœ„ì¹˜ ê³„ì‚°
            if target_camera not in self.extrinsic_data:
                return None
                
            # ğŸ”§ ì˜¬ë°”ë¥¸ ì¹´ë©”ë¼ ì›”ë“œ ì¢Œí‘œ ê³„ì‚°: H_cam2world ì‚¬ìš©
            extrinsic_H_world2cam = self.extrinsic_data[target_camera]['H_world2cam']
            extrinsic_position = extrinsic_H_world2cam[:3, 3]  # ì¹´ë©”ë¼ì˜ ì›”ë“œ ì¢Œí‘œ
            extrinsic_rotation = extrinsic_H_world2cam[:3, :3]
            
            # 3. ì°¨ì´ ê³„ì‚° (ë‘˜ ë‹¤ ì¹´ë©”ë¼ì˜ ì›”ë“œ ì¢Œí‘œê³„ ìƒ ìœ„ì¹˜/ìì„¸)
            position_diff = np.linalg.norm(tf_position - extrinsic_position)
            
            # íšŒì „ ì°¨ì´ ê³„ì‚° (ê°ë„ ì°¨ì´) - ë‘ íšŒì „ í–‰ë ¬ ê°„ì˜ ì°¨ì´
            rotation_diff_matrix = tf_rotation.T @ extrinsic_rotation
            rotation_diff_angle = np.arccos(np.clip((np.trace(rotation_diff_matrix) - 1) / 2, -1, 1))
            rotation_diff_degrees = np.degrees(rotation_diff_angle)
            
            return {
                'tf_position': tf_position,
                'extrinsic_position': extrinsic_position,
                'position_diff': position_diff,
                'rotation_diff_degrees': rotation_diff_degrees,
                'tf_rotation': tf_rotation,
                'extrinsic_rotation': extrinsic_rotation
            }
            
        except Exception as e:
            self.get_logger().debug(f"Could not compare {target_camera}: {e}")
            return None

    def log_validation_results(self, results):
        """ê²€ì¦ ê²°ê³¼ ë¡œê¹…"""
        
        self.get_logger().info("ğŸ” ========== Extrinsic vs TF Validation ==========")
        self.get_logger().info(f"ğŸ“ Reference camera: {self.world_reference_camera} (marker-based)")
        
        for camera_name, result in results.items():
            pos_diff = result['position_diff']
            rot_diff = result['rotation_diff_degrees']
            
            # ì„ê³„ê°’ ì„¤ì • (ì¡°ì • ê°€ëŠ¥)
            pos_threshold = 0.05  # 5cm
            rot_threshold = 5.0   # 5ë„
            
            pos_status = "âœ… OK" if pos_diff < pos_threshold else "âš ï¸ LARGE"
            rot_status = "âœ… OK" if rot_diff < rot_threshold else "âš ï¸ LARGE"
            
            self.get_logger().info(f"ğŸ“· {camera_name}:")
            self.get_logger().info(f"   Position diff: {pos_diff:.4f}m {pos_status}")
            self.get_logger().info(f"   Rotation diff: {rot_diff:.2f}Â° {rot_status}")
            
            # ìì„¸í•œ ìœ„ì¹˜ ì •ë³´ (ë‘˜ ë‹¤ ì¹´ë©”ë¼ì˜ ì›”ë“œ ì¢Œí‘œê³„ ìƒ ìœ„ì¹˜)
            tf_pos = result['tf_position']
            ext_pos = result['extrinsic_position']
            self.get_logger().info(f"   Marker-based cam pos: [{tf_pos[0]:.3f}, {tf_pos[1]:.3f}, {tf_pos[2]:.3f}]")
            self.get_logger().info(f"   Extrinsic cam pos:    [{ext_pos[0]:.3f}, {ext_pos[1]:.3f}, {ext_pos[2]:.3f}]")
        
        # ì „ì²´ ìš”ì•½
        max_pos_diff = max([r['position_diff'] for r in results.values()])
        max_rot_diff = max([r['rotation_diff_degrees'] for r in results.values()])
        
        overall_status = "âœ… GOOD" if max_pos_diff < 0.05 and max_rot_diff < 5.0 else "âš ï¸ CHECK NEEDED"
        self.get_logger().info(f"ğŸ“Š Overall: Max pos diff = {max_pos_diff:.4f}m, Max rot diff = {max_rot_diff:.2f}Â° {overall_status}")
        self.get_logger().info("ğŸ” ================================================")

    def get_camera_relative_position(self, source_camera, target_camera):
        """ë‘ ì¹´ë©”ë¼ ê°„ì˜ ìƒëŒ€ì  ìœ„ì¹˜ ê³„ì‚° (ë””ë²„ê¹…ìš©)"""
        
        try:
            # TFì—ì„œ ìƒëŒ€ ë³€í™˜ ê°€ì ¸ì˜¤ê¸°
            transform = self.tf_buffer.lookup_transform(
                f'{source_camera}_frame', f'{target_camera}_frame',
                rclpy.time.Time(), timeout=rclpy.duration.Duration(seconds=1.0)
            )
            
            relative_pos = np.array([
                transform.transform.translation.x,
                transform.transform.translation.y, 
                transform.transform.translation.z
            ])
            
            relative_quat = [
                transform.transform.rotation.x,
                transform.transform.rotation.y,
                transform.transform.rotation.z,
                transform.transform.rotation.w
            ]
            
            return relative_pos, relative_quat
            
        except Exception as e:
            self.get_logger().debug(f"Could not get relative position: {e}")
            return None, None

    def publish_robot_center(self, center, H_world2robot):
        """ë¡œë´‡ ì¤‘ì‹¬ ìœ„ì¹˜ ë°œí–‰"""
        msg = PoseStamped()
        msg.header = Header()
        msg.header.stamp = self.get_clock().now().to_msg()
        msg.header.frame_id = 'world'
        
        msg.pose.position.x = float(center[0])
        msg.pose.position.y = float(center[1])
        msg.pose.position.z = float(center[2])

        r_world2robot = H_world2robot[0:3, 0:3]
        rot = R.from_matrix(r_world2robot)
        quat = rot.as_quat()  # [x, y, z, w]
        msg.pose.orientation.x = quat[0]
        msg.pose.orientation.y = quat[1]   
        msg.pose.orientation.z = quat[2]
        msg.pose.orientation.w = quat[3]
        
        self.robot_center_pub.publish(msg)

    def project_world_to_image(self, world_point, camera_name):
        """ì›”ë“œ ì¢Œí‘œë¥¼ ì¹´ë©”ë¼ ì´ë¯¸ì§€ë¡œ íˆ¬ì˜"""
        
        camera_config = self.cameras[camera_name]
        H_world2cam = camera_config.get('H_world2cam')
        
        if H_world2cam is None or not camera_config['info_received']:
            return None
        
        try:
            # ì›”ë“œ â†’ ì¹´ë©”ë¼ ë³€í™˜
            world_point_homogeneous = np.append(world_point, 1)
            cam_point_homogeneous = H_world2cam @ world_point_homogeneous
            cam_point = cam_point_homogeneous[:3]
            
            if cam_point[2] <= 0:  # ì¹´ë©”ë¼ ë’¤ì— ìˆìŒ
                return None
            
            # ì¹´ë©”ë¼ â†’ ì´ë¯¸ì§€ íˆ¬ì˜
            image_points, _ = cv2.projectPoints(
                cam_point.reshape(1, 1, 3), np.zeros(3), np.zeros(3),
                camera_config['camera_matrix'], camera_config['dist_coeffs']
            )
            
            return image_points[0][0]
            
        except Exception as e:
            return None

    def visualize_results(self, image, detected_markers, camera_name):
        """ê²€ì¶œ ê²°ê³¼ ì‹œê°í™”"""
        
        # ê²€ì¶œëœ ë§ˆì»¤ë“¤ í‘œì‹œ
        for marker_id, data in detected_markers.items():
            corners = data['corners'][0]
            center = np.mean(corners, axis=0).astype(int)
            
            if marker_id == 10:
                # 10ë²ˆ ë§ˆì»¤ - ì›”ë“œ ì›ì 
                color = (255, 0, 0)
                label = f"World{marker_id}"
                cv2.polylines(image, [corners.astype(int)], True, (0, 255, 0), 2)
                cv2.putText(image, label, tuple(center), 
                        cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)
                self.draw_coordinate_axes(image, data['cam_rvec'], data['cam_tvec'], 0.05, camera_name)
            elif marker_id in self.robot_markers_local:
                # ë¡œë´‡ ë§ˆì»¤ë“¤
                color = (0, 0, 255)
                label = f"R{marker_id}"
                cv2.polylines(image, [corners.astype(int)], True, (0, 255, 255), 2)
                cv2.putText(image, label, tuple(center), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)

        # ë¡œë´‡ ì¤‘ì‹¬ í‘œì‹œ
        if (self.world_established and 
            self.latest_robot_center is not None and
            self.center_timestamp is not None and 
            time.time() - self.center_timestamp < 1.0):
            
            center_image = self.project_world_to_image(self.latest_robot_center, camera_name)
            if center_image is not None:
                center_pt = tuple(center_image.astype(int))
                cv2.circle(image, center_pt, 8, (0, 255, 255), -1)
                cv2.putText(image, "Robot", (center_pt[0]+15, center_pt[1]), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)

        # ìƒíƒœ ì •ë³´ í‘œì‹œ
        if self.world_from_marker:
            world_status = "World: Marker-based"
            world_color = (0, 255, 0)
        elif self.world_from_extrinsic:
            world_status = "World: Extrinsic-based"
            world_color = (0, 200, 255)
        else:
            world_status = "World: Not available"
            world_color = (0, 0, 255)
            
        cv2.putText(image, world_status, (10, 30), 
                cv2.FONT_HERSHEY_SIMPLEX, 0.7, world_color, 2)
        
        # ë¡œë´‡ ì¢Œí‘œ í‘œì‹œ
        if self.latest_robot_center is not None:
            coord_text = f"Robot: ({self.latest_robot_center[0]:.2f}, {self.latest_robot_center[1]:.2f}, {self.latest_robot_center[2]:.2f})"
            cv2.putText(image, coord_text, (10, 60), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)

        # ê²€ì¦ ìƒíƒœ í‘œì‹œ (ì›”ë“œ ê¸°ì¤€ ì¹´ë©”ë¼ê°€ ì•„ë‹Œ ê²½ìš°)
        if (self.world_from_marker and 
            self.world_reference_camera is not None and 
            camera_name != self.world_reference_camera and
            hasattr(self, 'validation_results') and 
            camera_name in self.validation_results):
            
            result = self.validation_results[camera_name]
            pos_diff = result['position_diff']
            rot_diff = result['rotation_diff_degrees']
            
            validation_color = (0, 255, 0) if pos_diff < 0.05 and rot_diff < 5.0 else (0, 165, 255)
            validation_text = f"Validation: Pos {pos_diff:.3f}m, Rot {rot_diff:.1f}Â°"
            cv2.putText(image, validation_text, (10, 90), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, validation_color, 1)

        # ì´ë¯¸ì§€ í‘œì‹œ
        cv2.imshow(f'{camera_name} - ArUco Detection', image)
        cv2.waitKey(1)

    def draw_coordinate_axes(self, image, rvec, tvec, length, camera_name):
        """ì¢Œí‘œì¶• ê·¸ë¦¬ê¸°"""
        camera_config = self.cameras[camera_name]
        
        if not camera_config['info_received']:
            return
            
        try:
            axis_points = np.float32([[0,0,0], [length,0,0], [0,length,0], [0,0,length]]).reshape(-1,3)
            
            imgpts, _ = cv2.projectPoints(axis_points, rvec, tvec, 
                                        camera_config['camera_matrix'], 
                                        camera_config['dist_coeffs'])
            
            imgpts = np.int32(imgpts).reshape(-1,2)
            origin = tuple(imgpts[0])
            
            # Xì¶• (ë¹¨ê°„ìƒ‰), Yì¶• (ì´ˆë¡ìƒ‰), Zì¶• (íŒŒë€ìƒ‰)
            cv2.arrowedLine(image, origin, tuple(imgpts[1]), (0,0,255), 2)
            cv2.arrowedLine(image, origin, tuple(imgpts[2]), (0,255,0), 2)
            cv2.arrowedLine(image, origin, tuple(imgpts[3]), (255,0,0), 2)
            
        except Exception:
            pass

def main(args=None):
    rclpy.init(args=args)
    detector = D435ArucoDetectorWithExtrinsic()
    
    try:
        rclpy.spin(detector)
    except KeyboardInterrupt:
        pass
    finally:
        cv2.destroyAllWindows()
        detector.destroy_node()
        rclpy.shutdown()

if __name__ == '__main__':
    main()
