import numpy as np
import cv2
import cv2.aruco as aruco
import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image, CameraInfo
from geometry_msgs.msg import PoseStamped, TransformStamped
from std_msgs.msg import Header
from cv_bridge import CvBridge
import time
import tf2_ros
from scipy.spatial.transform import Rotation as R
# from tf_transformations import quaternion_from_matrix

class D435ArucoDetector(Node):
    def __init__(self):
        super().__init__('d435_aruco_detector')
        
        # ë¡œë´‡ ë§ˆì»¤ë“¤ (0~3ë²ˆ) - ë¡œì»¬ ì¢Œí‘œê³„
        self.robot_markers_local = {
            0: np.array([0.3, 0.135, 0.0]),
            1: np.array([0.3, -0.135, 0.0]),
            2: np.array([-0.3, -0.135, 0.0]),
            3: np.array([-0.3, 0.135, 0.0])
        }
    
        self.marker_length = 0.075  # ë§ˆì»¤ í¬ê¸° 5cm
        
        # ì›”ë“œ ì¢Œí‘œê³„ ì„¤ì • ìƒíƒœ
        self.world_established = False
        self.camera_to_world_R = None
        self.camera_to_world_t = None
        
        # ì¹´ë©”ë¼ ì •ë³´
        self.camera_matrix = None
        self.dist_coeffs = None
        self.camera_info_received = False
        
        # ë¡œë´‡ ì¤‘ì‹¬ ì¶”ì 
        self.latest_robot_center = None
        self.center_timestamp = None
        
        self.aruco_50 = [0, 1,2,3]
        self.aruco_75 = [10]

        # ArUco ì„¤ì •
        self.aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_4X4_50)
        self.aruco_params = cv2.aruco.DetectorParameters()

        # ë³€í™˜ í–‰ë ¬ë“¤
        self.H_world2cam = None    # 10ë²ˆ ë§ˆì»¤ ê¸°ì¤€ ì›”ë“œâ†’ì¹´ë©”ë¼
        self.H_cam2robot = None    # ì¹´ë©”ë¼â†’ë¡œë´‡ ì¤‘ì‹¬
        self.H_world2robot = None  # ì›”ë“œâ†’ë¡œë´‡
        
        self.tf_broadcaster = tf2_ros.TransformBroadcaster(self)

        # êµ¬ë…ì ì„¤ì •
        self.create_subscription(
            Image, '/camera1/camera1/color/image_raw', 
            self.image_callback, 10
        )
        self.create_subscription(
            CameraInfo, '/camera1/camera1/color/camera_info',
            self.camera_info_callback, 10
        )
        
        # ë°œí–‰ì
        self.robot_center_pub = self.create_publisher(
            PoseStamped, '/robot_center', 10
        )
        
        self.get_logger().info("D435 ArUco Detector initialized")

    def camera_info_callback(self, msg):
        """ì¹´ë©”ë¼ ë‚´ë¶€ ë§¤ê°œë³€ìˆ˜ ìˆ˜ì‹ """
        if not self.camera_info_received:
            self.camera_matrix = np.array(msg.k).reshape(3, 3)
            self.dist_coeffs = np.array(msg.d)
            self.camera_info_received = True
            self.get_logger().info("Camera intrinsics received")

    def image_callback(self, msg):
        """ì´ë¯¸ì§€ ì²˜ë¦¬ ë° ArUco ê²€ì¶œ"""
        if not self.camera_info_received:
            return
            
        bridge = CvBridge()
        cv_image = bridge.imgmsg_to_cv2(msg, desired_encoding='bgr8')
        gray = cv2.cvtColor(cv_image, cv2.COLOR_BGR2GRAY)

        # ArUco ë§ˆì»¤ ê²€ì¶œ
        detector = aruco.ArucoDetector(self.aruco_dict, self.aruco_params)
        corners, ids, _ = detector.detectMarkers(gray)

        if ids is None:
            return

        # ê¸°ë³¸ í¬ì¦ˆ ì¶”ì • (ì¹´ë©”ë¼ ì¢Œí‘œê³„)
        try:
            rvecs, tvecs, _ = cv2.aruco.estimatePoseSingleMarkers(
                corners, self.marker_length, self.camera_matrix, self.dist_coeffs
            )
        except Exception as e:
            self.get_logger().error(f"Pose estimation failed: {e}")
            return

        # ê²€ì¶œëœ ë§ˆì»¤ ì •ë¦¬
        detected_markers = {}
        for i, marker_id in enumerate(ids.flatten()):
            detected_markers[marker_id] = {
                'cam_tvec': tvecs[i].reshape(3),
                'cam_rvec': rvecs[i].reshape(3),
                'corners': corners[i]
            }

        # ğŸ†• ë‹¨ìˆœí•œ ì›”ë“œ ì¢Œí‘œê³„ ì„¤ì •: 10ë²ˆ ë§ˆì»¤ = ì›”ë“œ ì›ì 
        H_world2cam = None
        robot_markers_cam = {}

        for marker_id, data in detected_markers.items():
            # âœ… 10ë²ˆ ë§ˆì»¤ë¥¼ ì›”ë“œ ì¢Œí‘œê³„ë¡œ ì„¤ì • (ë‹¨ìˆœ!)
            if marker_id == 10:
                rvec = data['cam_rvec']
                tvec = data['cam_tvec']
                H_cam2world = np.eye(4)
                R, _ = cv2.Rodrigues(rvec)
                H_cam2world[0:3, 0:3] = R
                H_cam2world[0:3, 3] = tvec
                # ë§ˆì»¤ 10ì˜ ì¢Œí‘œê³„ = ì›”ë“œ ì¢Œí‘œê³„
                # H_cam2marker10 ì˜ ì—­ë³€í™˜ = H_marker10â†’cam = H_worldâ†’cam
                H_world2cam = np.linalg.inv(H_cam2world)
                self.H_world2cam = H_world2cam  # í´ë˜ìŠ¤ ë³€ìˆ˜ì— ì €ì¥
                self.world_established = True
                self.broadcast_world_transform(H_world2cam, msg.header.stamp)
                self.get_logger().info("âœ… Marker 10 set as world origin")
                self.get_logger().info(f"Marker 10 position (cam): {tvec}")
            
            # ë¡œë´‡ ë§ˆì»¤ë“¤ ìˆ˜ì§‘
            elif marker_id in self.robot_markers_local:
                rvec = data['cam_rvec']
                tvec = data['cam_tvec']
                R, _ = cv2.Rodrigues(rvec)
                H_cam2marker = np.eye(4)
                H_cam2marker[0:3, 0:3] = R
                H_cam2marker[0:3, 3] = tvec
                robot_markers_cam[marker_id] = {
                    'position': tvec,
                    'rotation': R,
                    'transform': H_cam2marker
                }

        # 10ë²ˆ ë§ˆì»¤ê°€ ì—†ìœ¼ë©´ ì›”ë“œ ì¢Œí‘œê³„ ì—†ìŒ
        if not self.world_established:
            self.get_logger().warn("âŒ Marker 10 not detected - no world coordinate system")
            self.visualize_results(cv_image, detected_markers)
            return

        # ğŸ¤– ë¡œë´‡ ì¤‘ì‹¬ ê³„ì‚° (ìˆ˜ì •ë¨)
        if len(robot_markers_cam) > 0:
            # ë¡œë´‡ ë§ˆì»¤ë“¤ì˜ ì¤‘ì 
            robot_positions = [data['position'] for data in robot_markers_cam.values()]
            robot_center_cam = np.mean(robot_positions, axis=0)
            
            # âœ… ì˜¬ë°”ë¥¸ ë¡œë´‡ íšŒì „ ê³„ì‚°
            robot_rotation_cam = self.calculate_robot_rotation_simple(robot_markers_cam)
            
            # H_cam2robot
            H_cam2robot = np.eye(4)
            H_cam2robot[0:3, 0:3] = robot_rotation_cam  # âœ… ì§ì ‘ ì‚¬ìš© (Rodrigues ë¶ˆí•„ìš”)
            H_cam2robot[0:3, 3] = robot_center_cam
            self.H_cam2robot = H_cam2robot
                        
            # H_world2robot ê³„ì‚°
            H_world2robot = H_world2cam @ H_cam2robot
            robot_center_world = H_world2robot[:3, 3]
            
            self.broadcast_robot_transform(H_world2robot, msg.header.stamp)
            self.latest_robot_center = robot_center_world
            self.center_timestamp = time.time()
            
            self.get_logger().info(f"ğŸ¤– Robot center (cam): {robot_center_cam}")
            self.get_logger().info(f"ğŸŒ Robot center (world): {robot_center_world}")
            
            # ë°œí–‰
            self.publish_robot_center(robot_center_world, len(robot_markers_cam))


        # ì‹œê°í™”
        self.visualize_results(cv_image, detected_markers)

    def project_world_to_image_simple(self, world_point):
        """10ë²ˆ ë§ˆì»¤ ê¸°ì¤€ ì›”ë“œ ì¢Œí‘œë¥¼ ì´ë¯¸ì§€ë¡œ íˆ¬ì˜"""
        
        if not hasattr(self, 'H_world2cam') or self.H_world2cam is None:
            return None
        
        try:
            # ì›”ë“œ â†’ ì¹´ë©”ë¼ ë³€í™˜
            world_point_homogeneous = np.append(world_point, 1)
            cam_point_homogeneous = self.H_world2cam @ world_point_homogeneous
            cam_point = cam_point_homogeneous[:3]
            
            if cam_point[2] <= 0:  # ì¹´ë©”ë¼ ë’¤ì— ìˆìŒ
                return None
            
            # ì¹´ë©”ë¼ â†’ ì´ë¯¸ì§€ íˆ¬ì˜
            image_points, _ = cv2.projectPoints(
                cam_point.reshape(1, 1, 3), np.zeros(3), np.zeros(3),
                self.camera_matrix, self.dist_coeffs
            )
            
            return image_points[0][0]
            
        except Exception as e:
            self.get_logger().error(f"Projection failed: {e}")
            return None
        


    def publish_robot_center(self, center, num_markers):
        """ë¡œë´‡ ì¤‘ì‹¬ ìœ„ì¹˜ ë°œí–‰"""
        msg = PoseStamped()
        msg.header = Header()
        msg.header.stamp = self.get_clock().now().to_msg()
        msg.header.frame_id = 'world'
        
        msg.pose.position.x = float(center[0])
        msg.pose.position.y = float(center[1])
        msg.pose.position.z = float(center[2])
        msg.pose.orientation.w = 1.0
        
        self.robot_center_pub.publish(msg)
        
        self.get_logger().info(
            f"Published robot center: ({center[0]:.3f}, {center[1]:.3f}, {center[2]:.3f}) "
            f"from {num_markers} markers"
        )
        
    def broadcast_robot_transform(self, H_world2robot, timestamp):
        """ë¡œë´‡ ì¢Œí‘œê³„ tf ë¸Œë¡œë“œìºìŠ¤íŠ¸"""
        # ì›”ë“œ â†’ ë¡œë´‡ ë³€í™˜ì„ ë¡œë´‡ â†’ ì›”ë“œë¡œ ë³€í™˜
        H_robot2world = np.linalg.inv(H_world2robot)
        
        t = TransformStamped()
        t.header.stamp = timestamp
        t.header.frame_id = 'world'
        t.child_frame_id = 'robot_center'
        
        # ìœ„ì¹˜
        t.transform.translation.x = float(H_world2robot[0, 3])
        t.transform.translation.y = float(H_world2robot[1, 3])
        t.transform.translation.z = float(H_world2robot[2, 3])
        
        # íšŒì „
        R_mat = H_robot2world[0:3, 0:3]
        rot = R.from_matrix(R_mat)
        quat = rot.as_quat()  # [x, y, z, w]
        t.transform.rotation.x = quat[0]
        t.transform.rotation.y = quat[1]
        t.transform.rotation.z = quat[2]
        t.transform.rotation.w = quat[3]
        
        self.tf_broadcaster.sendTransform(t)

    def broadcast_world_transform(self, H_world2cam, timestamp):
        """ì›”ë“œ ì¢Œí‘œê³„ tf ë¸Œë¡œë“œìºìŠ¤íŠ¸"""
        # ì¹´ë©”ë¼ â†’ ì›”ë“œ ë³€í™˜
        H_cam2world = np.linalg.inv(H_world2cam)
        
        t = TransformStamped()
        t.header.stamp = timestamp
        t.header.frame_id = 'camera_link'
        t.child_frame_id = 'world'
        
        # ìœ„ì¹˜
        t.transform.translation.x = float(H_cam2world[0, 3])
        t.transform.translation.y = float(H_cam2world[1, 3])
        t.transform.translation.z = float(H_cam2world[2, 3])
        
        # íšŒì „
        R_mat = H_cam2world[0:3, 0:3]
        rot = R.from_matrix(R_mat)
        quat = rot.as_quat()  # [x, y, z, w]
        t.transform.rotation.x = quat[0]
        t.transform.rotation.y = quat[1]
        t.transform.rotation.z = quat[2]
        t.transform.rotation.w = quat[3]
        
        self.tf_broadcaster.sendTransform(t)

    def calculate_robot_rotation_simple(self, robot_markers_cam):
        """ê°„ë‹¨í•œ ì•„ì›ƒë¼ì´ì–´ ì œê±° + íšŒì „ í‰ê· """
        
        if len(robot_markers_cam) <= 1:
            return list(robot_markers_cam.values())[0]['rotation']
        
        from scipy.spatial.transform import Rotation as R_scipy
        
        # Quaternion ë³€í™˜
        rotations_data = []
        for marker_id, data in robot_markers_cam.items():
            rot_matrix = data['rotation']
            r = R_scipy.from_matrix(rot_matrix)
            quat = r.as_quat()
            rotations_data.append((marker_id, quat, rot_matrix))
        
        # ê°„ë‹¨í•œ ì•„ì›ƒë¼ì´ì–´ ì œê±°: ì²« ë²ˆì§¸ì™€ ë„ˆë¬´ ë‹¤ë¥¸ ê²ƒ ì œê±°
        reference_quat = rotations_data[0][1]
        valid_rotations = []
        
        for marker_id, quat, rot_matrix in rotations_data:
            # ê°ë„ ì°¨ì´ ê³„ì‚°
            dot_product = np.abs(np.dot(reference_quat, quat))
            angle_diff = 2 * np.arccos(np.clip(dot_product, 0, 1))
            
            if angle_diff <= 0.5:  # ì•½ 30ë„ ì´ë‚´
                valid_rotations.append(quat)
            else:
                self.get_logger().warn(f"âš ï¸ Marker {marker_id} removed: angle diff {np.degrees(angle_diff):.1f}Â°")
        
        # í‰ê·  ê³„ì‚°
        if len(valid_rotations) > 0:
            mean_quat = np.mean(valid_rotations, axis=0)
            mean_quat = mean_quat / np.linalg.norm(mean_quat)
            return R_scipy.from_quat(mean_quat).as_matrix()
        else:
            return rotations_data[0][2]  # ì²« ë²ˆì§¸ ë§ˆì»¤ ì‚¬ìš©
    
    def visualize_results(self, image, detected_markers):
        """ê²€ì¶œ ê²°ê³¼ì™€ ì¢Œí‘œê³„ ì¶• ì‹œê°í™”"""
        
        # ê²€ì¶œëœ ë§ˆì»¤ë“¤ í‘œì‹œ
        for marker_id, data in detected_markers.items():
            corners = data['corners'][0]
            
            
            
            # ë§ˆì»¤ ID í‘œì‹œ - ìƒ‰ìƒ êµ¬ë¶„
            center = np.mean(corners, axis=0).astype(int)
            
            if marker_id == 10:
                # 10ë²ˆ ë§ˆì»¤ - ì›”ë“œ ì›ì  (íŒŒë€ìƒ‰)
                color = (255, 0, 0)
                label = f"World{marker_id}"
            # elif marker_id in self.robot_markers_local:
            #     # ë¡œë´‡ ë§ˆì»¤ë“¤ (ë¹¨ê°„ìƒ‰)
            #     color = (0, 0, 255)
            #     label = f"R{marker_id}"
                # ë§ˆì»¤ ê²½ê³„ ê·¸ë¦¬ê¸°
                cv2.polylines(image, [corners.astype(int)], True, (0, 255, 0), 2)
                cv2.putText(image, label, tuple(center), 
                        cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)
            
                # # ğŸ†• ë§ˆì»¤ë³„ ì¢Œí‘œì¶• ê·¸ë¦¬ê¸°
                self.draw_coordinate_axes(image, data['cam_rvec'], data['cam_tvec'], 0.05)

        # ğŸ¤– ë¡œë´‡ ì¤‘ì‹¬ê³¼ ë¡œë´‡ ì¢Œí‘œì¶• í‘œì‹œ
        if (self.world_established and 
            self.latest_robot_center is not None and
            self.center_timestamp is not None and 
            time.time() - self.center_timestamp < 1.0):
            
            # ë¡œë´‡ ì¤‘ì‹¬ì„ ì´ë¯¸ì§€ë¡œ íˆ¬ì˜
            center_image = self.project_world_to_image_simple(self.latest_robot_center)
            if center_image is not None:
                center_pt = tuple(center_image.astype(int))
                
                # ë¡œë´‡ ì¤‘ì‹¬ í‘œì‹œ
                cv2.circle(image, center_pt, 8, (0, 255, 255), -1)
                cv2.putText(image, "Robot", (center_pt[0]+15, center_pt[1]), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
                
                # ğŸ†• ë¡œë´‡ ì¢Œí‘œì¶• ê·¸ë¦¬ê¸°
                self.draw_robot_coordinate_axes(image)

        # ğŸ“Š ê°„ë‹¨í•œ ìƒíƒœ ì •ë³´ë§Œ
        world_status = "World: OK" if self.world_established else "World: No Marker 10"
        world_color = (0, 255, 0) if self.world_established else (0, 0, 255)
        cv2.putText(image, world_status, (10, 30), 
                cv2.FONT_HERSHEY_SIMPLEX, 0.7, world_color, 2)
        
        # ë¡œë´‡ ì¢Œí‘œ (ê°„ë‹¨íˆ)
        if self.latest_robot_center is not None:
            coord_text = f"Robot: ({self.latest_robot_center[0]:.2f}, {self.latest_robot_center[1]:.2f}, {self.latest_robot_center[2]:.2f})"
            cv2.putText(image, coord_text, (10, 60), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)

        # ì´ë¯¸ì§€ í‘œì‹œ
        cv2.imshow('ArUco Detection with Coordinate Axes', image)
        cv2.waitKey(1)
    def draw_robot_coordinate_axes(self, image):
        """ë¡œë´‡ ì¢Œí‘œì¶•ì„ draw_coordinate_axes í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ì„œ ê·¸ë¦¬ê¸°"""
        
        if self.H_cam2robot is None:
            return
        
        try:
            # H_cam2robotì—ì„œ rvec, tvec ì¶”ì¶œ
            robot_rotation = self.H_cam2robot[0:3, 0:3]  # íšŒì „ í–‰ë ¬
            robot_translation = self.H_cam2robot[0:3, 3]  # ì´ë™ ë²¡í„°
            
            # íšŒì „ í–‰ë ¬ â†’ rodrigues ë²¡í„° ë³€í™˜
            robot_rvec, _ = cv2.Rodrigues(robot_rotation)
            robot_tvec = robot_translation
            
            # âœ… ê¸°ì¡´ draw_coordinate_axes í•¨ìˆ˜ ì‚¬ìš©
            self.draw_coordinate_axes(image, robot_rvec, robot_tvec, length=0.08)
            
            self.get_logger().info("âœ… Robot coordinate axes drawn successfully")
            
        except Exception as e:
            self.get_logger().warn(f"âŒ Failed to draw robot coordinate axes: {e}")
            
    def draw_coordinate_axes(self, image, rvec, tvec, length=0.03):
        """ë§ˆì»¤ì˜ ì¢Œí‘œì¶•ì„ ì´ë¯¸ì§€ì— ê·¸ë¦¬ê¸°"""
        try:
            # ì¶• í¬ì¸íŠ¸ë“¤ ì •ì˜ (ë§ˆì»¤ ì¤‘ì‹¬ì—ì„œ ê° ì¶• ë°©í–¥ìœ¼ë¡œ)
            axis_points = np.float32([[0,0,0], [length,0,0], [0,length,0], [0,0,length]]).reshape(-1,3)
            
            # 3D ì ë“¤ì„ ì´ë¯¸ì§€ë¡œ íˆ¬ì˜
            imgpts, _ = cv2.projectPoints(axis_points, rvec, tvec, 
                                        self.camera_matrix, self.dist_coeffs)
            
            imgpts = np.int32(imgpts).reshape(-1,2)
            
            # ì›ì 
            origin = tuple(imgpts[0])
            
            # Xì¶• (ë¹¨ê°„ìƒ‰)
            cv2.arrowedLine(image, origin, tuple(imgpts[1]), (0,0,255), 2)
            # Yì¶• (ì´ˆë¡ìƒ‰)  
            cv2.arrowedLine(image, origin, tuple(imgpts[2]), (0,255,0), 2)
            # Zì¶• (íŒŒë€ìƒ‰)
            cv2.arrowedLine(image, origin, tuple(imgpts[3]), (255,0,0), 2)
            
        except Exception as e:
            pass  # ì¡°ìš©íˆ ë¬´ì‹œ

def main(args=None):
    rclpy.init(args=args)
    detector = D435ArucoDetector()
    
    try:
        rclpy.spin(detector)
    except KeyboardInterrupt:
        pass
    finally:
        cv2.destroyAllWindows()
        detector.destroy_node()
        rclpy.shutdown()

if __name__ == '__main__':
    main()